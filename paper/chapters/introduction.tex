The image caption generation task is at the cross-section between Computer Vision (CV) and Natural Language Processing (NLP). It requires the computer to understand a visual scene  and describe it into a grammatically correct Natural sentence. Practical use cases vary from automated describing of images to visually impaired people \cite{mazzoni_2019} to context based image retrieval.

Show Attend and Tell (S.A.T.) proposed by \citeauthor{xu2016show} is an end-to-end deep learning approach that tries to solve the image caption generation problem. It combines an attention mechanism with LSTM to generate sentences that describe the given image. Achieving good BLEU scores on Flickr8K, Flickr30K\cite{Flickr8k} and COCO\cite{lin2015microsoft} datasets. Although the scores are not state-of-the-art\cite{DBLP:journals/corr/abs-2107-06912} anymore. This model is chosen because it is small and thus can be run locally, and has publicly available implementations \cite{sgrvinod}.

Machine learning models often are susceptible to adversarial attacks, where the input is modified in such a way that the model is not able to produce a correct result or worse, a specific incorrect output. When these models are applied in a practical setting they need to be robust against these adversarial attacks. Moreover, if the model is robust against adversarial attacks it also is more robust against noise, and thus a more useful model.

\subsection*{Research Questions}
This research investigates the susceptibility of S.A.T. against adversarial samples that are visually close but generate completely different descriptions as output. To ensure that the images are visually close noise will be added to an original image.
The research questions boil down to:
\begin{itemize}
    \item Is S.A.T. susceptible to adversarial attacks using noise?
    \item Can the noise be crafted in such a way that it can steer the output.
\end{itemize}




