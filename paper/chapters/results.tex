\subsection*{Adversarial Samples}
Adversarial samples are generated using the iterative version of Fast Gradient Sign method as shown in equation \ref{IterativeMethod}. With $N=10$ satisfactory results can be achieved, however higher $N$ results in even better results for the same $\epsilon$. Higher epsilons did not have an effect on BLEU score beyond $0.08$ as can be seen in figure \ref{adv_bleu_score}. This is in contrast to the cosine similarity as it does decrease further for the higher $\epsilon$.

\begin{figure*}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/adversarial_bleu_score_over_epsilon.png} % first figure itself
        \caption{Average BLEU score}
        \label{adv_bleu_score}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/adversarial_cosine_similarity_heatmap.png} % second figure itself
        \caption{Cosine similarity vs epsilon (Axis is not correct yet)}
        \label{adv_cosine_similarity}
    \end{minipage}
\end{figure*}

\begin{figure*}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/caption_teddy_normal.png} % first figure itself
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/caption_adv_teddy_bear_0.02.png} % second figure itself
    \end{minipage}
    \caption{Clean Image (left), Adversarial Image $\epsilon=0.02, N=10$ (right)}
    \label{adv_example_caption}
\end{figure*}

As can be seen in figure \ref{adv_example_caption} the attention of S.A.T, even though not explicitly attacked, is not as focused as on the clean image. This is especially visible in images that are successfully attacked. Images for which the model still is able to generate decent captions, still have a good focus on the main subjects in the image (\ref{adv_example_caption_tennis}).



\begin{figure*}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/caption_clean_tennis_court.png} % first figure itself
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/caption_adv_tennis_court_0.02.png} % second figure itself
    \end{minipage}
    \caption{Clean Image (left), Adversarial Image $\epsilon=0.02, N=10$ (right)}
    \label{adv_example_caption_tennis}
\end{figure*}

\subsection*{Distracting Samples}
To distract the model, adversarial samples are created using the iterative method (EQ. \ref{IterativeMethod}) and the distraction adversarial loss (EQ. \ref{distraction_loss}). The amount of iterations was experimentally found to be good enough in most cases at 100, in which more would result in better distraction at the cost of longer running times. The top left pixel was chosen to focus the attention on as the model focus least on it (\ref{average_attention_clean}) (albeit slightly) during the clean images. With an epsilon of 0.04 satisfactory results are achieved. The attention of the model clearly focused on the top left on average as can be seen in figure \ref{average_attention_adv}. With the perturbation at most 0.04 the image is visually almost identical to the human eye (figure \ref{dist_adv_example_img}).

\begin{figure*}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/distraction_attention_epsilon_0.png} % first figure itself
        \caption{Average attention on clean images}
        \label{average_attention_clean}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/distraction_attention_epsilon_0.04.png} % second figure itself
        \caption{Average attention on adversarial images with $\epsilon$=0.04 at 100 iterations}
        \label{average_attention_adv}
    \end{minipage}
\end{figure*}

\begin{figure*}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/distraction_adv_sample_0.png} % first figure itself
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/distraction_adv_sample_0.04.png} % second figure itself
    \end{minipage}
    \caption{Clean Image (left), Adversarial Image $\epsilon=0.04, N=100$ (right)}
    \label{dist_adv_example_img}
\end{figure*}

The attention and sentence generation for figure \ref{dist_adv_example_img} are visualized in figure \ref{adv_example_att}. The model is not completely distracted and still attends to other parts of the image, however they are not clearly a single object relating to the word that is generated. During the generations of the last few words the attention is focused almost solely on the top left part.

\begin{figure*}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/caption_distraction_adv_sample_0.png} % first figure itself
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/caption_distraction_adv_sample_0.04.png} % second figure itself
    \end{minipage}
    \caption{Attention on Clean Image (left) and Adversarial Image $\epsilon=0.04, N=100$ (right)}
    \label{adv_example_att}
\end{figure*}


\begin{figure}
    \includegraphics[width=0.9\textwidth]{figures/distraction_bleu_score_over_epsilon.png}
    \caption{BLEU score during distraction over epsilon}
\end{figure}



% Although I currently don't have complete results. I do have some initial samples that worked. I am still in the process of calculating the BLEU score and cosine similarity over the whole datasets.
% Preliminary results images:

