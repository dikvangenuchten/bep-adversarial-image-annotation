\subsection*{Adversarial Samples}
Adversarial samples are generated using the iterative version of the Fast Gradient Sign method as shown in equation \ref{eq:iterative_method}. With $N=10$ satisfactory results can be achieved, however higher $N$ results in even better results for the same $\epsilon$. Higher epsilons did not affect the BLEU score beyond $0.08$ significantly as can be seen in figure \ref{adv_bleu_score}.

\begin{figure}[h]
    \centering
    \subfloat[a][Average BLEU score for adversarial samples.]{
        \includegraphics[width=0.48\textwidth]{figures/adversarial_average_bleu_score.png}
        \label{adv_bleu_score}

    }
    \vspace{\floatsep}
    \subfloat[b][Cosine similarity vs epsilon]{
        \includegraphics[width=0.48\textwidth]{figures/adversarial_average_cosine_sim.png} % second figure itself
        \label{adv_cosine_similarity}

    }
    \caption{Scores over epsilon for adversarial samples. Note the log x-scale.}
\end{figure}

\begin{figure}[h]
    \centering
    \subfloat[a][$\epsilon$=0.000]{
        \includegraphics[width=0.48\textwidth]{figures/caption_teddy_normal.png}
    }
    \vspace{\floatsep}
    \subfloat[b][$\epsilon=0.020, N=10$]{
        \includegraphics[width=0.48\textwidth]{figures/caption_adv_teddy_bear_0.02.png} % second figure itself
    }
    \caption{Attention visualized for a clean (a) and an adversarial image (b) of a successful attack.}
    \label{adv_example_caption}
\end{figure}

% \begin{figure*}[H]
%     \centering
%     \begin{minipage}{0.45\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{figures/caption_teddy_normal.png} % first figure itself
%     \end{minipage}\hfill
%     \begin{minipage}{0.45\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{figures/caption_adv_teddy_bear_0.02.png} % second figure itself
%     \end{minipage}
%     \caption{Clean Image (left), Adversarial Image $\epsilon=0.02, N=10$ (right)}
%     \label{adv_example_caption}
% \end{figure*}

As can be seen in figure \ref{adv_example_caption} the attention of S.A.T, even though not explicitly attacked, is not as focused as on the clean image. This is especially visible in images that are successfully attacked. Images for which the model still is able to generate decent captions, still have a good focus on the main subjects in the image (\ref{adv_example_caption_tennis}).


\begin{figure}[H]
    \centering
    \subfloat[a][$\epsilon$=0.000]{
        \includegraphics[width=0.48\textwidth]{figures/caption_clean_tennis_court.png}
    }
    \vspace{\floatsep}
    \subfloat[b][$\epsilon=0.020, N=100$]{
        \includegraphics[width=0.48\textwidth]{figures/caption_adv_tennis_court_0.02.png} % second figure itself
    }
    \caption{Attention visualized for a clean (a) and an adversarial image (b) of an unsuccessful attack.}
    \label{adv_example_caption_tennis}
\end{figure}

% \begin{figure*}[H]
%     \centering
%     \begin{minipage}{0.45\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{figures/caption_clean_tennis_court.png} % first figure itself
%     \end{minipage}\hfill
%     \begin{minipage}{0.45\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{figures/caption_adv_tennis_court_0.02.png} % second figure itself
%     \end{minipage}
%     \caption{Clean Image (left), Adversarial Image $\epsilon=0.02, N=10$ (right)}
%     \label{adv_example_caption_tennis}
% \end{figure*}

\subsection*{Distracting Samples}
To distract the model, adversarial samples are created using the iterative method (EQ. \ref{eq:iterative_method}) and the distraction adversarial loss (EQ. \ref{distraction_loss}). The number of iterations was experimentally found to be good enough in most cases at 100, in which more would result in better distraction at the cost of longer running times. The adversarial attention targets the left top pixel. On the given dataset the attention is nicely divided with all parts of the image getting close to 0.005\footnote[1]{$attention / number\_of\_latent\_pixels = 1 / 196 = 0.005$} of the average attention per pixel. With an epsilon of 0.04 satisfactory results are achieved. The attention of the model is focused on the top-left on average as can be seen in figure \ref{average_attention_adv}. It gets attented to about 4x as much as before. With the perturbation at most 0.04 the image is visually identical to the human eye (figure \ref{fig:full_img_clean_field}).

\begin{figure}[H]
    \centering
    \subfloat[a][Average attention on clean images]{
        \includegraphics[width=0.48\textwidth]{figures/distraction_attention_epsilon_0.png}
        \label{average_attention_clean}
    }
    \vspace{\floatsep}
    \subfloat[b][Average attention on adversarial images with $\epsilon$=0.04 at 100 iterations]{
        \includegraphics[width=0.48\textwidth]{figures/distraction_attention_epsilon_0.04.png} % second figure itself
        \label{average_attention_adv}
    }
    \caption{Average attention visualized for clean (a) and adversarial images (b)}
    \label{average_attention}
\end{figure}


The attention and sentence generation for figure \ref{fig:full_img_clean_field} are visualized in figure \ref{fig:distract_field_all}. There is no disturbance visual between the clean and adversarial image. However, for the clean image the attention is focused on the correct parts of the image, while the model is completely distracted and attends solely to the top-left part on the adversarial image.

\begin{figure*}[ht]
    \centering
    \subfloat[a][Clean Image]{\includegraphics[width=0.45\textwidth]{figures/Distract/e0.000_n100/img_34.jpg}
        \label{fig:full_img_clean_field}
    }
    \vspace{\floatsep}
    \subfloat[a][Adversarial Image $epsilon=0.040, N=100$]{\includegraphics[width=0.45\textwidth]{figures/Distract/e0.040_n100/img_34.jpg}
        \label{fig:full_img_distract_field}
    }
    \vspace{\floatsep}
    \subfloat[a][Clean Image with attention]{\includegraphics[width=0.45\textwidth]{figures/Distract/e0.000_n100/caption_34.png}
        \label{fig:attention_clean_field}
    }
    \vspace{\floatsep}
    \subfloat[a][Adversarial Image $epsilon=0.040, N=100$]{\includegraphics[width=0.45\textwidth]{figures/Distract/e0.040_n100/caption_34.png}
        \label{fig:attention_distract_field}
    }
    \caption{Successful distracting the model.}
    \label{fig:distract_field_all}
\end{figure*}

Both the BLEU score and cosine similarity go down with higher values of epsilon, however, there are diminishing returns. Furthermore, with the higher values of epsilon, the image will eventually be unrecognizable, and thus is it not reasonable to expect a sensible output

\begin{figure*}[h]
    \subfloat[a][Average BLEU score]{
        \includegraphics[width=0.45\textwidth]{figures/Distract/plot_bleu_scores_IterativeAdversarial.jpg}}
    \vspace{\floatsep}
    \subfloat[a][Average cosine similarity]{\includegraphics[width=0.45\textwidth]{figures/adversarial_average_cosine_sim.png}}
    \caption{BLEU score and cosine similarity during distraction over epsilon}
\end{figure*}
