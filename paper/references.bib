 @misc{venkatesh,
  title   = {
             Automatic image annotation using deep learning representations: Proceedings of the 5th ACM on International Conference on Multimedia Retrieval
             },
  url     = {https://dl.acm.org/doi/pdf/10.1145/2671188.2749391},
  journal = {ACM Conferences},
  author  = {Venkatesh N. Murthy, Venkatesh N. and Amherst, University of Massachusetts and Subhransu Maji University of Massachusetts Amherst and Maji, Subhransu and R. Manmatha University of Massachusetts Amherst and Manmatha, R. and University, Carnegie Mellon and Kong, City University of Hong and University, Fudan and et al.             },
  year    = {2015},
  month   = {Jun}
}
@misc{goodfellow2015explaining,
  title         = {Explaining and Harnessing Adversarial Examples},
  author        = {Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
  year          = {2015},
  eprint        = {1412.6572},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}
@article{cheng_zhang_fu_tu_li_2018,
  title   = {A survey and analysis on Automatic Image Annotation},
  volume  = {79},
  doi     = {10.1016/j.patcog.2018.02.017},
  journal = {Pattern Recognition},
  author  = {Cheng, Qimin and Zhang, Qian and Fu, Peng and Tu, Conghuan and Li, Sen},
  year    = {2018},
  pages   = {242–259}
} 
@misc{szegedy2014intriguing,
  title         = {Intriguing properties of neural networks},
  author        = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
  year          = {2014},
  eprint        = {1312.6199},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{xu2016show,
  title         = {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
  author        = {Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhutdinov and Richard Zemel and Yoshua Bengio},
  year          = {2016},
  eprint        = {1502.03044},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{lin2015microsoft,
  title         = {Microsoft COCO: Common Objects in Context},
  author        = {Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
  year          = {2015},
  eprint        = {1405.0312},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{Flickr8k,
  title      = {Flickr8k Dataset},
  keywords   = {},
  author     = {Micah Hodosh and Peter Young and Julia Hockenmaier},
  abstract   = {8,000 photos and up to 5 captions for each photo.
                
                We introduce a new benchmark collection for sentence-based image description and search, consisting of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events. … The images were chosen from six different Flickr groups, and tend not to contain any well-known people or locations, but were manually selected to depict a variety of scenes and situations
                
                https://i.imgur.com/6RxAndT.png
                
                ## Citation
                
                Hodosh, Micah, Peter Young, and Julia Hockenmaier. "Framing image description as a ranking task: Data, models and evaluation metrics." Journal of Artificial Intelligence Research 47 (2013): 853-899.
                
                },
  terms      = {},
  license    = {},
  superseded = {},
  url        = {}
}
 @article{papineni_roukos_ward_zhu_2001,
  title   = {Bleu},
  doi     = {10.3115/1073083.1073135},
  journal = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics  - ACL '02},
  author  = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  year    = {2001}
}
 @misc{mazzoni_2019,
  title     = {Using AI to give people who are blind the "full picture"},
  url       = {https://blog.google/outreach-initiatives/accessibility/get-image-descriptions/},
  journal   = {Google},
  publisher = {Google},
  author    = {Mazzoni, Dominic},
  year      = {2019},
  month     = {Oct}
}
@article{DBLP:journals/corr/abs-2107-06912,
  author     = {Matteo Stefanini and
                Marcella Cornia and
                Lorenzo Baraldi and
                Silvia Cascianelli and
                Giuseppe Fiameni and
                Rita Cucchiara},
  title      = {From Show to Tell: {A} Survey on Image Captioning},
  journal    = {CoRR},
  volume     = {abs/2107.06912},
  year       = {2021},
  url        = {https://arxiv.org/abs/2107.06912},
  eprinttype = {arXiv},
  eprint     = {2107.06912},
  timestamp  = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2107-06912.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

 @misc{sgrvinod,
  title   = {Sgrvinod/a-pytorch-tutorial-to-image-captioning: Show, attend, and tell: A pytorch tutorial to image captioning},
  url     = {https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning},
  journal = {GitHub},
  author  = {Sgrvinod}
} 



@article{DBLP:journals/corr/abs-1803-11175,
  author     = {Daniel Cer and
                Yinfei Yang and
                Sheng{-}yi Kong and
                Nan Hua and
                Nicole Limtiaco and
                Rhomni St. John and
                Noah Constant and
                Mario Guajardo{-}Cespedes and
                Steve Yuan and
                Chris Tar and
                Yun{-}Hsuan Sung and
                Brian Strope and
                Ray Kurzweil},
  title      = {Universal Sentence Encoder},
  journal    = {CoRR},
  volume     = {abs/1803.11175},
  year       = {2018},
  url        = {http://arxiv.org/abs/1803.11175},
  eprinttype = {arXiv},
  eprint     = {1803.11175},
  timestamp  = {Mon, 13 Aug 2018 16:46:40 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1803-11175.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{Kurakin,
  doi       = {10.48550/ARXIV.1607.02533},
  url       = {https://arxiv.org/abs/1607.02533},
  author    = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Cryptography and Security (cs.CR), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adversarial examples in the physical world},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Hongge,
  author     = {Hongge Chen and
                Huan Zhang and
                Pin{-}Yu Chen and
                Jinfeng Yi and
                Cho{-}Jui Hsieh},
  title      = {Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning},
  journal    = {CoRR},
  volume     = {abs/1712.02051},
  year       = {2017},
  url        = {http://arxiv.org/abs/1712.02051},
  eprinttype = {arXiv},
  eprint     = {1712.02051},
  timestamp  = {Sat, 31 Aug 2019 16:23:05 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1712-02051.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{Ilyas2019features,
  doi       = {10.48550/ARXIV.1905.02175},
  url       = {https://arxiv.org/abs/1905.02175},
  author    = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  keywords  = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adversarial Examples Are Not Bugs, They Are Features},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{LIU2022103612,
  title    = {An efficient adversarial example generation algorithm based on an accelerated gradient iterative fast gradient},
  journal  = {Computer Standards & Interfaces},
  volume   = {82},
  pages    = {103612},
  year     = {2022},
  issn     = {0920-5489},
  doi      = {https://doi.org/10.1016/j.csi.2021.103612},
  url      = {https://www.sciencedirect.com/science/article/pii/S0920548921001069},
  author   = {Jiabao Liu and Qixiang Zhang and Kanghua Mo and Xiaoyu Xiang and Jin Li and Debin Cheng and Rui Gao and Beishui Liu and Kongyang Chen and Guanjie Wei},
  keywords = {Iterative fast gradient, Adversarial examples, Transferable},
  abstract = {Most existing deep neural networks are susceptible to the influence of adversarial examples, which may cause them to output incorrect prediction results. An adversarial example is the addition of small noise disturbances to the input data samples, which will deceive the classification. Generally, these modifications are very small noise disturbances, which are not easily noticed by the human eye. However, most existing adversarial attacks achieve only low success rates in typical black-box settings, where the attackers have no prior knowledge about the model structures and/or model parameters. To tackle this problem, we propose an iterative algorithm based on an acceleration gradient to enhance the adversary attack. Our method accumulates the gradient of the loss function in each iteration and uses the next gradient information to influence the future gradient. We also introduce the scaling invariance principle of a deep neural network to optimize the input images for black-box attacks. In addition, to handle the drawbacks of a traditional iterative fast gradient sign method, we further present two gradient optimization methods. Experimental results on the ImageNet dataset show that our attack methods can achieve good transferability. In addition, those models obtained by integrated adversarial training with strong defense capability are also quite vulnerable to our black-box attack.}
}
@inproceedings{EvaluatingRobustness,
  author    = {Carlini, Nicholas and Wagner, David},
  booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
  title     = {Towards Evaluating the Robustness of Neural Networks},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {39-57},
  doi       = {10.1109/SP.2017.49}
}

@misc{showandtell,
  doi       = {10.48550/ARXIV.1411.4555},
  url       = {https://arxiv.org/abs/1411.4555},
  author    = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Show and Tell: A Neural Image Caption Generator},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{AdversarialAttacksOnFace,
  doi       = {10.48550/ARXIV.1805.12302},
  url       = {https://arxiv.org/abs/1805.12302},
  author    = {Bose, Avishek Joey and Aarabi, Parham},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adversarial Attacks on Face Detectors using Neural Net based Constrained Optimization},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{AdversarialFasterRCNN,
  author    = {Liu, Zhenghao and Peng, Wenyu and Zhou, Jun and Wu, Zifeng and Zhang, Jintao and Zhang, Yunchun},
  title     = {MI-FGSM on Faster R-CNN Object Detector},
  year      = {2020},
  isbn      = {9781450389075},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3447450.3447455},
  doi       = {10.1145/3447450.3447455},
  abstract  = {The adversarial examples show the vulnerability of deep neural networks, which makes adversarial attacks widely concerned. However, most of the attack methods are based on image classification model. In this paper, we use Momentum Iterative Fast Gradient Sign Method (MI-FGSM), which stabilize optimization and escape from poor local maxima, to generate adversarial examples on the Faster R-CNN object detector. We have made some improvements on the previous object detection attack methods. The best current attack method, Project Gradient Descent (PGD) on object detection, starts from a random value, resulting in the uncertainty of the attack result. In contrast, our attacks are more stable and powerful in both white-box attacks and black-box attacks, and can better adapt to various neural network architectures. Experiment on Pascal VOC2007 shows that, under same setting of white-box attack, PGD has 0.23% mean average precision (mAP) on Faster R-CNN with VGG16, while our method achieves 0.17%. In addition, we analyze the difference between classification and detection attacks, and find that in addition to misclassification, the adversarial examples produced by detection models can also lead to mislocation.},
  booktitle = {2020 The 4th International Conference on Video and Image Processing},
  pages     = {27–32},
  numpages  = {6},
  keywords  = {White-box attack, Object detection, Black-box attack, Adversarial attack},
  location  = {Xi'an, China},
  series    = {ICVIP 2020}
}
@article{DBLP:journals/corr/abs-1907-10310,
  author     = {Haichao Zhang and
                Jianyu Wang},
  title      = {Towards Adversarially Robust Object Detection},
  journal    = {CoRR},
  volume     = {abs/1907.10310},
  year       = {2019},
  url        = {http://arxiv.org/abs/1907.10310},
  eprinttype = {arXiv},
  eprint     = {1907.10310},
  timestamp  = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1907-10310.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{https://doi.org/10.48550/arxiv.1611.01236,
  doi       = {10.48550/ARXIV.1611.01236},
  url       = {https://arxiv.org/abs/1611.01236},
  author    = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Cryptography and Security (cs.CR), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adversarial Machine Learning at Scale},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{9237700,
  author    = {Xu, Jin},
  booktitle = {2020 IEEE 11th International Conference on Software Engineering and Service Science (ICSESS)},
  title     = {Generate Adversarial Examples by Nesterov-momentum Iterative Fast Gradient Sign Method},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {244-249},
  doi       = {10.1109/ICSESS49938.2020.9237700}
}
@misc{xie2019improving,
  title         = {Improving Transferability of Adversarial Examples with Input Diversity},
  author        = {Cihang Xie and Zhishuai Zhang and Yuyin Zhou and Song Bai and Jianyu Wang and Zhou Ren and Alan Yuille},
  year          = {2019},
  eprint        = {1803.06978},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{kingma2017adam,
  title         = {Adam: A Method for Stochastic Optimization},
  author        = {Diederik P. Kingma and Jimmy Ba},
  year          = {2017},
  eprint        = {1412.6980},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{10.2307/2984087,
  issn      = {00359246},
  url       = {http://www.jstor.org/stable/2984087},
  abstract  = {This paper deals first with the relationship between the theory of probability and the theory of rational behaviour. A method is then suggested for encouraging people to make accurate probability estimates, a connection with the theory of information being mentioned. Finally Wald's theory of statistical decision functions is summarised and generalised and its relation to the theory of rational behaviour is discussed.},
  author    = {I. J. Good},
  journal   = {Journal of the Royal Statistical Society. Series B (Methodological)},
  number    = {1},
  pages     = {107--114},
  publisher = {[Royal Statistical Society, Wiley]},
  title     = {Rational Decisions},
  urldate   = {2022-06-04},
  volume    = {14},
  year      = {1952}
}

@misc{attention_bahdanau,
  doi       = {10.48550/ARXIV.1409.0473},
  url       = {https://arxiv.org/abs/1409.0473},
  author    = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2107.03050,
  doi       = {10.48550/ARXIV.2107.03050},
  url       = {https://arxiv.org/abs/2107.03050},
  author    = {Aafaq, Nayyer and Akhtar, Naveed and Liu, Wei and Shah, Mubarak and Mian, Ajmal},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Controlled Caption Generation for Images Through Adversarial Attacks},
  publisher = {arXiv},
  year      = {2021},
  copyright = {Creative Commons Zero v1.0 Universal}
}
@article{lstm,
  author  = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  year    = {1997},
  month   = {12},
  pages   = {1735-80},
  title   = {Long Short-term Memory},
  volume  = {9},
  journal = {Neural computation},
  doi     = {10.1162/neco.1997.9.8.1735}
}

@misc{nltk,
  url       = {https://www.nltk.org/_modules/nltk/translate/bleu_score.html},
  journal   = {NLTK},
  author    = {Bird, Steven, Edward Loper and Ewan Klein},
  year      = {2009},
  publisher = {O Reilly Media Inc.},
  title     = {Natural Language Processing with Python.}
} 

@incollection{NEURIPS2019_9015,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {8024--8035},
  year      = {2019},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@misc{https://doi.org/10.48550/arxiv.1810.04101,
  doi       = {10.48550/ARXIV.1810.04101},
  url       = {https://arxiv.org/abs/1810.04101},
  author    = {Bazzani, Loris and Domhan, Tobias and Hieber, Felix},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Image Captioning as Neural Machine Translation Task in SOCKEYE},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
